{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b9a6d70",
   "metadata": {},
   "source": [
    "# summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2be460c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string  import punctuation \n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from tkinter import ttk ,messagebox\n",
    "from tkinter.scrolledtext import *\n",
    "import tkinter.filedialog\n",
    "from collections import Counter\n",
    "from googletrans import Translator\n",
    "from tkinter import messagebox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3586595b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a55911a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summarize(): \n",
    "    text = str(entry.get('1.0', tk.END))\n",
    "    doc=nlp(text)\n",
    "    tokens = [token.text.lower() for token in doc # extract the text and conver it to lowercase \n",
    "              if not token.is_stop and  # not stopwords\n",
    "              not token.is_punct and token.text !=\"\\n\" ]    # not punctuation        # not \\n\n",
    "    \n",
    "    \n",
    "    \n",
    "    tokens1=[]\n",
    "\n",
    "    stopwords = list(STOP_WORDS)\n",
    "        \n",
    "    allowed_pos = ['ADJ', 'PROPN', 'VERB', 'NOUN']\n",
    "\n",
    "    for token in doc:\n",
    "\n",
    "            if token.text in stopwords or token.text in punctuation:\n",
    "                continue\n",
    "\n",
    "            if token.pos_ in allowed_pos:\n",
    "                \n",
    "                tokens1.append(token.text)\n",
    "                \n",
    "                \n",
    "    from collections import Counter            \n",
    "    word_freq = Counter(tokens)\n",
    "    max_freq = max(word_freq.values())\n",
    "    for word in word_freq.keys():\n",
    "        \n",
    "        word_freq[word] = word_freq[word]/max_freq\n",
    "        \n",
    "        \n",
    "        \n",
    "    sent_token = [sent.text for sent in doc.sents]\n",
    "    \n",
    "    sent_score = {}\n",
    "\n",
    "    for sent in sent_token: # iterates over each sentence \n",
    "\n",
    "        for word in sent.split(): #The inner loop splits each sentence into words using split()\n",
    "\n",
    "            if word.lower() in word_freq.keys(): # it checks if the lowercase version of the word is in the word_freq dictionary\n",
    "\n",
    "                if sent not in sent_score.keys():\n",
    "\n",
    "                    sent_score[sent] = word_freq[word] #If the sentence (sent) is not already a key in sent_score, \n",
    "                                                        #it initializes its score to the frequency of the current word.\n",
    "                        \n",
    "                                                        #If the sentence is already in sent_score, \n",
    "                                                        #it adds the frequency of the current word to its existing score.\n",
    "                else:\n",
    "\n",
    "                     sent_score[sent] += word_freq[word]\n",
    "\n",
    "    from heapq import nlargest\n",
    "\n",
    "    num_sentences = 2\n",
    "\n",
    "    n = nlargest(num_sentences, sent_score, key=sent_score.get)\n",
    "\n",
    "    \" \".join(n)  # separating each sentence by a space.\n",
    "    result = '\\nSummary: {}'.format(n)\n",
    "    tab1_display.insert(tk.END, result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b91413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_summary():\n",
    "    text = displayed_file.get('1.0',tk.END)\n",
    "    doc=nlp(text)\n",
    "    tokens = [token.text.lower() for token in doc # extract the text and conver it to lowercase \n",
    "              if not token.is_stop and  # not stopwords\n",
    "              not token.is_punct and token.text != \" \\n \" ]    # not punctuation        # not \\n\n",
    "    \n",
    "    \n",
    "    \n",
    "    tokens1=[]\n",
    "\n",
    "    stopwords = list(STOP_WORDS)\n",
    "        \n",
    "    allowed_pos = ['ADJ', 'PROPN', 'VERB', 'NOUN']\n",
    "\n",
    "    for token in doc:\n",
    "\n",
    "            if token.text in stopwords or token.text in punctuation:\n",
    "                continue\n",
    "\n",
    "            if token.pos_ in allowed_pos:\n",
    "                \n",
    "                tokens1.append(token.text)\n",
    "                \n",
    "                \n",
    "    from collections import Counter            \n",
    "    word_freq = Counter(tokens)\n",
    "    max_freq = max(word_freq.values())\n",
    "    for word in word_freq.keys():\n",
    "        \n",
    "        word_freq[word] = word_freq[word]/max_freq\n",
    "        \n",
    "        \n",
    "        \n",
    "    sent_token = [sent.text for sent in doc.sents]\n",
    "    \n",
    "    sent_score = {}\n",
    "\n",
    "    for sent in sent_token: # iterates over each sentence \n",
    "\n",
    "        for word in sent.split(): #The inner loop splits each sentence into words using split()\n",
    "\n",
    "            if word.lower() in word_freq.keys(): # it checks if the lowercase version of the word is in the word_freq dictionary\n",
    "\n",
    "                if sent not in sent_score.keys():\n",
    "\n",
    "                    sent_score[sent] = word_freq[word] #If the sentence (sent) is not already a key in sent_score, \n",
    "                                                        #it initializes its score to the frequency of the current word.\n",
    "                        \n",
    "                                                        #If the sentence is already in sent_score, \n",
    "                                                        #it adds the frequency of the current word to its existing score.\n",
    "                else:\n",
    "\n",
    "                     sent_score[sent] += word_freq[word]\n",
    "\n",
    "    from heapq import nlargest\n",
    "\n",
    "    num_sentences = 2\n",
    "\n",
    "    n = nlargest(num_sentences, sent_score, key=sent_score.get)\n",
    "\n",
    "    \"  \".join(n)  # separating each sentence by a space\n",
    "    \n",
    "    result = '\\nSummary:{}'.format(n)\n",
    "    tab2_display_text.insert(tk.END,result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3d0f9b",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "216b615d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#remove'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\ascom\\anaconda3\\lib\\site-packages (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from wordcloud) (1.24.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from wordcloud) (9.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from wordcloud) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (23.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Requirement already satisfied: spacy in c:\\users\\ascom\\anaconda3\\lib\\site-packages (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: unknown command \"install textblob\" - maybe you meant \"install\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\ascom\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ascom\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -i https://pypi.anaconda.org/berber/simple tweet-preprocessor  #remove URLs, hashtags \n",
    "!pip install wordcloud\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install beautifulsoup4\n",
    "!pip install textblob\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0196fc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0  Positive  im getting on borderlands and i will murder yo...\n",
       "1  Positive  I am coming to the borders and I will kill you...\n",
       "2  Positive  im getting on borderlands and i will kill you ...\n",
       "3  Positive  im coming on borderlands and i will murder you...\n",
       "4  Positive  im getting on borderlands 2 and i will murder ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# disable warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #suppresses all warnings that are normally issued by Python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('twitter_sentiment.csv', header=None, index_col=[0])\n",
    "#index_col=[0] specifies that the first column should be used as the index of the DataFrame.\n",
    "df = df[[2,3]].reset_index(drop=True)\n",
    "#resets the index of the DataFrame, dropping the old index and generating a new one starting from 0.\n",
    "df.columns = ['sentiment', 'text']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d05f9a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75682 entries, 0 to 75681\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sentiment  75682 non-null  object\n",
      " 1   text       74996 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d57553e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment      0\n",
       "text         686\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5cfec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.dropna(inplace=True) #removes any rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ada70fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Negative      22624\n",
       "Positive      20932\n",
       "Neutral       18393\n",
       "Irrelevant    13047\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a3bafcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='count'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['sentiment'].value_counts().plot(kind='pie', autopct='%1.0f%%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aa67413",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[\"text\"]\n",
    "y=df[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a579fe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as p  #remove URLs, hashtags \n",
    "X_preprocessed = X.apply(lambda tweet: p.clean(tweet))# must be NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d57430",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ba62e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline#used to chain multiple estimators (such as transformers and classifiers)\n",
    "#n_estimators=100: number of decision trees in the forest\n",
    "#n_jobs=-1:the number of jobs to run in parallel for both fit and predict operations.\n",
    "#Setting it to -1 means that all available CPU cores will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c42c4435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59996,), (15000,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['sentiment'], test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63f46ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(stop_words=[&#x27;does&#x27;, &#x27;than&#x27;, &#x27;hereupon&#x27;,\n",
       "                                             &#x27;together&#x27;, &#x27;amount&#x27;, &#x27;seem&#x27;,\n",
       "                                             &#x27;same&#x27;, &#x27;alone&#x27;, &#x27;you&#x27;, &#x27;even&#x27;,\n",
       "                                             &#x27;name&#x27;, &#x27;since&#x27;, &#x27;various&#x27;, &#x27;well&#x27;,\n",
       "                                             &#x27;hundred&#x27;, &#x27;none&#x27;, &#x27;fifteen&#x27;,\n",
       "                                             &#x27;until&#x27;, &#x27;other&#x27;, &#x27;his&#x27;, &#x27;was&#x27;,\n",
       "                                             &#x27;mostly&#x27;, &#x27;latterly&#x27;, &#x27;throughout&#x27;,\n",
       "                                             &#x27;either&#x27;, &#x27;therefore&#x27;, &#x27;the&#x27;,\n",
       "                                             &#x27;however&#x27;, &#x27;did&#x27;, &quot;&#x27;m&quot;, ...])),\n",
       "                (&#x27;clf&#x27;, RandomForestClassifier(n_jobs=-1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(stop_words=[&#x27;does&#x27;, &#x27;than&#x27;, &#x27;hereupon&#x27;,\n",
       "                                             &#x27;together&#x27;, &#x27;amount&#x27;, &#x27;seem&#x27;,\n",
       "                                             &#x27;same&#x27;, &#x27;alone&#x27;, &#x27;you&#x27;, &#x27;even&#x27;,\n",
       "                                             &#x27;name&#x27;, &#x27;since&#x27;, &#x27;various&#x27;, &#x27;well&#x27;,\n",
       "                                             &#x27;hundred&#x27;, &#x27;none&#x27;, &#x27;fifteen&#x27;,\n",
       "                                             &#x27;until&#x27;, &#x27;other&#x27;, &#x27;his&#x27;, &#x27;was&#x27;,\n",
       "                                             &#x27;mostly&#x27;, &#x27;latterly&#x27;, &#x27;throughout&#x27;,\n",
       "                                             &#x27;either&#x27;, &#x27;therefore&#x27;, &#x27;the&#x27;,\n",
       "                                             &#x27;however&#x27;, &#x27;did&#x27;, &quot;&#x27;m&quot;, ...])),\n",
       "                (&#x27;clf&#x27;, RandomForestClassifier(n_jobs=-1))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(stop_words=[&#x27;does&#x27;, &#x27;than&#x27;, &#x27;hereupon&#x27;, &#x27;together&#x27;, &#x27;amount&#x27;,\n",
       "                            &#x27;seem&#x27;, &#x27;same&#x27;, &#x27;alone&#x27;, &#x27;you&#x27;, &#x27;even&#x27;, &#x27;name&#x27;,\n",
       "                            &#x27;since&#x27;, &#x27;various&#x27;, &#x27;well&#x27;, &#x27;hundred&#x27;, &#x27;none&#x27;,\n",
       "                            &#x27;fifteen&#x27;, &#x27;until&#x27;, &#x27;other&#x27;, &#x27;his&#x27;, &#x27;was&#x27;, &#x27;mostly&#x27;,\n",
       "                            &#x27;latterly&#x27;, &#x27;throughout&#x27;, &#x27;either&#x27;, &#x27;therefore&#x27;,\n",
       "                            &#x27;the&#x27;, &#x27;however&#x27;, &#x27;did&#x27;, &quot;&#x27;m&quot;, ...])</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_jobs=-1)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(stop_words=['does', 'than', 'hereupon',\n",
       "                                             'together', 'amount', 'seem',\n",
       "                                             'same', 'alone', 'you', 'even',\n",
       "                                             'name', 'since', 'various', 'well',\n",
       "                                             'hundred', 'none', 'fifteen',\n",
       "                                             'until', 'other', 'his', 'was',\n",
       "                                             'mostly', 'latterly', 'throughout',\n",
       "                                             'either', 'therefore', 'the',\n",
       "                                             'however', 'did', \"'m\", ...])),\n",
       "                ('clf', RandomForestClassifier(n_jobs=-1))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = list(STOP_WORDS)\n",
    "clf = Pipeline([('tfidf', TfidfVectorizer(stop_words=stopwords)), ('clf', RandomForestClassifier(n_estimators=100, n_jobs=-1))])\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5aeeaa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9121333333333334\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "predictions = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9880a6",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd4ebd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(stop_words=[&#x27;does&#x27;, &#x27;than&#x27;, &#x27;hereupon&#x27;,\n",
       "                                             &#x27;together&#x27;, &#x27;amount&#x27;, &#x27;seem&#x27;,\n",
       "                                             &#x27;same&#x27;, &#x27;alone&#x27;, &#x27;you&#x27;, &#x27;even&#x27;,\n",
       "                                             &#x27;name&#x27;, &#x27;since&#x27;, &#x27;various&#x27;, &#x27;well&#x27;,\n",
       "                                             &#x27;hundred&#x27;, &#x27;none&#x27;, &#x27;fifteen&#x27;,\n",
       "                                             &#x27;until&#x27;, &#x27;other&#x27;, &#x27;his&#x27;, &#x27;was&#x27;,\n",
       "                                             &#x27;mostly&#x27;, &#x27;latterly&#x27;, &#x27;throughout&#x27;,\n",
       "                                             &#x27;either&#x27;, &#x27;therefore&#x27;, &#x27;the&#x27;,\n",
       "                                             &#x27;however&#x27;, &#x27;did&#x27;, &quot;&#x27;m&quot;, ...])),\n",
       "                (&#x27;model&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(stop_words=[&#x27;does&#x27;, &#x27;than&#x27;, &#x27;hereupon&#x27;,\n",
       "                                             &#x27;together&#x27;, &#x27;amount&#x27;, &#x27;seem&#x27;,\n",
       "                                             &#x27;same&#x27;, &#x27;alone&#x27;, &#x27;you&#x27;, &#x27;even&#x27;,\n",
       "                                             &#x27;name&#x27;, &#x27;since&#x27;, &#x27;various&#x27;, &#x27;well&#x27;,\n",
       "                                             &#x27;hundred&#x27;, &#x27;none&#x27;, &#x27;fifteen&#x27;,\n",
       "                                             &#x27;until&#x27;, &#x27;other&#x27;, &#x27;his&#x27;, &#x27;was&#x27;,\n",
       "                                             &#x27;mostly&#x27;, &#x27;latterly&#x27;, &#x27;throughout&#x27;,\n",
       "                                             &#x27;either&#x27;, &#x27;therefore&#x27;, &#x27;the&#x27;,\n",
       "                                             &#x27;however&#x27;, &#x27;did&#x27;, &quot;&#x27;m&quot;, ...])),\n",
       "                (&#x27;model&#x27;, LogisticRegression())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(stop_words=[&#x27;does&#x27;, &#x27;than&#x27;, &#x27;hereupon&#x27;, &#x27;together&#x27;, &#x27;amount&#x27;,\n",
       "                            &#x27;seem&#x27;, &#x27;same&#x27;, &#x27;alone&#x27;, &#x27;you&#x27;, &#x27;even&#x27;, &#x27;name&#x27;,\n",
       "                            &#x27;since&#x27;, &#x27;various&#x27;, &#x27;well&#x27;, &#x27;hundred&#x27;, &#x27;none&#x27;,\n",
       "                            &#x27;fifteen&#x27;, &#x27;until&#x27;, &#x27;other&#x27;, &#x27;his&#x27;, &#x27;was&#x27;, &#x27;mostly&#x27;,\n",
       "                            &#x27;latterly&#x27;, &#x27;throughout&#x27;, &#x27;either&#x27;, &#x27;therefore&#x27;,\n",
       "                            &#x27;the&#x27;, &#x27;however&#x27;, &#x27;did&#x27;, &quot;&#x27;m&quot;, ...])</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(stop_words=['does', 'than', 'hereupon',\n",
       "                                             'together', 'amount', 'seem',\n",
       "                                             'same', 'alone', 'you', 'even',\n",
       "                                             'name', 'since', 'various', 'well',\n",
       "                                             'hundred', 'none', 'fifteen',\n",
       "                                             'until', 'other', 'his', 'was',\n",
       "                                             'mostly', 'latterly', 'throughout',\n",
       "                                             'either', 'therefore', 'the',\n",
       "                                             'however', 'did', \"'m\", ...])),\n",
       "                ('model', LogisticRegression())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model building\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "stopwords = list(STOP_WORDS)\n",
    "model= Pipeline([('tfidf', TfidfVectorizer(stop_words=stopwords)), ('model',LogisticRegression())])\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ead95fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7930666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = model.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abc44a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sentiment_Analysis():\n",
    "    text = entry.get('1.0',tk.END)\n",
    "    x=clf.predict([text])\n",
    "    tab1_display.insert(tk.END, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4245f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sentiment_Analysis_file():\n",
    "    text = displayed_file.get('1.0',tk.END)\n",
    "    x=clf.predict([text])\n",
    "    tab2_display_text.insert(tk.END,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c296fce",
   "metadata": {},
   "source": [
    "# named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e82fbfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8aeb834f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>NaN</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>NaN</td>\n",
       "      <td>responded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>NaN</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>NaN</td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sentence #           Word  POS Tag\n",
       "0        Sentence: 1      Thousands  NNS   O\n",
       "1                NaN             of   IN   O\n",
       "2                NaN  demonstrators  NNS   O\n",
       "3                NaN           have  VBP   O\n",
       "4                NaN        marched  VBN   O\n",
       "...              ...            ...  ...  ..\n",
       "1048570          NaN           they  PRP   O\n",
       "1048571          NaN      responded  VBD   O\n",
       "1048572          NaN             to   TO   O\n",
       "1048573          NaN            the   DT   O\n",
       "1048574          NaN         attack   NN   O\n",
       "\n",
       "[1048575 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset= pd.read_csv(\"ner_dataset.csv\",encoding=\"latin1\" )\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "584a6c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =dataset.fillna(method =\"ffill\")\n",
    "\n",
    "dataset[\"Sentence #\"] = LabelEncoder().fit_transform(dataset[\"Sentence #\"] )\n",
    "\n",
    "dataset.dropna(inplace=True) #removes any rows with missing values\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X = dataset[\"Word\"]  # Input features (words)\n",
    "y = dataset['Tag']  # Target variable (NER labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99500e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 30773)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(encoding='latin-1', ngram_range=(1, 2),stop_words='english')\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "# Check the shapes of X_train, X_test, y_train, y_test\n",
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d79899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6cc664b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "regressor = LogisticRegression()\n",
    "mod = regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77a752b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9226474024271034\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = mod.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72f41ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "x = DecisionTreeClassifier()\n",
    "moodel = x.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8be36aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9336385094056219\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = moodel.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30c81f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner():\n",
    "    text = entry.get('1.0', tk.END)\n",
    "    text_tokenized = word_tokenize(text)  # Tokenize the input text\n",
    "    for word in text_tokenized:\n",
    "        text_tfidf = tfidf.transform([word])  # Transform each tokenized word into TF-IDF vectors\n",
    "        prediction = moodel.predict(text_tfidf)\n",
    "        # Print the word along with its predicted NER label\n",
    "        tab1_display.insert(tk.END, f\"{word}: {prediction}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37e41691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nerf():\n",
    "    text = entry.get('1.0', tk.END)\n",
    "    text_tokenized = word_tokenize(text)  # Tokenize the input text\n",
    "    for word in text_tokenized:\n",
    "        text_tfidf = tfidf.transform([word])  # Transform each tokenized word into TF-IDF vectors\n",
    "        prediction = moodel.predict(text_tfidf)\n",
    "        # Print the word along with its predicted NER label\n",
    "        tab2_display_text.insert(tk.END, prediction )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca76686",
   "metadata": {},
   "source": [
    "# translation from english to arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0d958f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000\n",
      "Number of unique input tokens: 73\n",
      "Number of unique output tokens: 107\n",
      "Max sequence length for inputs: 44\n",
      "Max sequence length for outputs: 67\n",
      "Epoch 1/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 93ms/step - accuracy: 0.7177 - loss: 1.5652 - val_accuracy: 0.6236 - val_loss: 1.5705\n",
      "Epoch 2/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - accuracy: 0.7555 - loss: 0.9858 - val_accuracy: 0.6225 - val_loss: 1.4523\n",
      "Epoch 3/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 94ms/step - accuracy: 0.7607 - loss: 0.9210 - val_accuracy: 0.6311 - val_loss: 1.3844\n",
      "Epoch 4/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.7792 - loss: 0.8436 - val_accuracy: 0.6669 - val_loss: 1.2624\n",
      "Epoch 5/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.7882 - loss: 0.8111 - val_accuracy: 0.6710 - val_loss: 1.2368\n",
      "Epoch 6/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.7940 - loss: 0.7804 - val_accuracy: 0.6837 - val_loss: 1.1959\n",
      "Epoch 7/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 0.8011 - loss: 0.7451 - val_accuracy: 0.6838 - val_loss: 1.1783\n",
      "Epoch 8/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 96ms/step - accuracy: 0.8033 - loss: 0.7342 - val_accuracy: 0.6928 - val_loss: 1.1595\n",
      "Epoch 9/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 94ms/step - accuracy: 0.8066 - loss: 0.7208 - val_accuracy: 0.6901 - val_loss: 1.1435\n",
      "Epoch 10/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 94ms/step - accuracy: 0.8087 - loss: 0.7085 - val_accuracy: 0.6872 - val_loss: 1.1440\n",
      "Epoch 11/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 94ms/step - accuracy: 0.8105 - loss: 0.7015 - val_accuracy: 0.6986 - val_loss: 1.1095\n",
      "Epoch 12/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 95ms/step - accuracy: 0.8124 - loss: 0.6890 - val_accuracy: 0.6985 - val_loss: 1.1059\n",
      "Epoch 13/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - accuracy: 0.8159 - loss: 0.6747 - val_accuracy: 0.7021 - val_loss: 1.0941\n",
      "Epoch 14/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - accuracy: 0.8174 - loss: 0.6691 - val_accuracy: 0.7062 - val_loss: 1.0801\n",
      "Epoch 15/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 98ms/step - accuracy: 0.8178 - loss: 0.6664 - val_accuracy: 0.7052 - val_loss: 1.0775\n",
      "Epoch 16/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 99ms/step - accuracy: 0.8191 - loss: 0.6590 - val_accuracy: 0.7085 - val_loss: 1.0633\n",
      "Epoch 17/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - accuracy: 0.8226 - loss: 0.6451 - val_accuracy: 0.7101 - val_loss: 1.0578\n",
      "Epoch 18/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.8230 - loss: 0.6430 - val_accuracy: 0.7147 - val_loss: 1.0472\n",
      "Epoch 19/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 0.8241 - loss: 0.6409 - val_accuracy: 0.7138 - val_loss: 1.0436\n",
      "Epoch 20/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.8261 - loss: 0.6329 - val_accuracy: 0.7183 - val_loss: 1.0347\n",
      "Epoch 21/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - accuracy: 0.8272 - loss: 0.6292 - val_accuracy: 0.7139 - val_loss: 1.0365\n",
      "Epoch 22/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.8289 - loss: 0.6206 - val_accuracy: 0.7191 - val_loss: 1.0237\n",
      "Epoch 23/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.8303 - loss: 0.6162 - val_accuracy: 0.7216 - val_loss: 1.0142\n",
      "Epoch 24/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.8311 - loss: 0.6139 - val_accuracy: 0.7223 - val_loss: 1.0131\n",
      "Epoch 25/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 0.8318 - loss: 0.6102 - val_accuracy: 0.7220 - val_loss: 1.0139\n",
      "Epoch 26/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - accuracy: 0.8338 - loss: 0.6006 - val_accuracy: 0.7218 - val_loss: 1.0084\n",
      "Epoch 27/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.8344 - loss: 0.5991 - val_accuracy: 0.7223 - val_loss: 1.0072\n",
      "Epoch 28/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.8366 - loss: 0.5913 - val_accuracy: 0.7233 - val_loss: 1.0020\n",
      "Epoch 29/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - accuracy: 0.8369 - loss: 0.5884 - val_accuracy: 0.7293 - val_loss: 0.9859\n",
      "Epoch 30/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 0.8389 - loss: 0.5806 - val_accuracy: 0.7297 - val_loss: 0.9843\n",
      "Epoch 31/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 0.8391 - loss: 0.5807 - val_accuracy: 0.7296 - val_loss: 0.9838\n",
      "Epoch 32/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - accuracy: 0.8384 - loss: 0.5807 - val_accuracy: 0.7316 - val_loss: 0.9766\n",
      "Epoch 33/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 0.8403 - loss: 0.5754 - val_accuracy: 0.7356 - val_loss: 0.9632\n",
      "Epoch 34/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - accuracy: 0.8425 - loss: 0.5673 - val_accuracy: 0.7340 - val_loss: 0.9663\n",
      "Epoch 35/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - accuracy: 0.8445 - loss: 0.5618 - val_accuracy: 0.7378 - val_loss: 0.9585\n",
      "Epoch 36/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 94ms/step - accuracy: 0.8447 - loss: 0.5592 - val_accuracy: 0.7327 - val_loss: 0.9736\n",
      "Epoch 37/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - accuracy: 0.8462 - loss: 0.5528 - val_accuracy: 0.7371 - val_loss: 0.9543\n",
      "Epoch 38/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - accuracy: 0.8470 - loss: 0.5497 - val_accuracy: 0.7401 - val_loss: 0.9485\n",
      "Epoch 39/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 95ms/step - accuracy: 0.8480 - loss: 0.5439 - val_accuracy: 0.7401 - val_loss: 0.9499\n",
      "Epoch 40/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 95ms/step - accuracy: 0.8491 - loss: 0.5439 - val_accuracy: 0.7409 - val_loss: 0.9476\n",
      "Epoch 41/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 97ms/step - accuracy: 0.8505 - loss: 0.5372 - val_accuracy: 0.7431 - val_loss: 0.9390\n",
      "Epoch 42/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 0.8502 - loss: 0.5385 - val_accuracy: 0.7439 - val_loss: 0.9432\n",
      "Epoch 43/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - accuracy: 0.8519 - loss: 0.5318 - val_accuracy: 0.7444 - val_loss: 0.9371\n",
      "Epoch 44/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.8534 - loss: 0.5259 - val_accuracy: 0.7429 - val_loss: 0.9412\n",
      "Epoch 45/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - accuracy: 0.8549 - loss: 0.5216 - val_accuracy: 0.7462 - val_loss: 0.9329\n",
      "Epoch 46/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - accuracy: 0.8557 - loss: 0.5195 - val_accuracy: 0.7449 - val_loss: 0.9367\n",
      "Epoch 47/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 100ms/step - accuracy: 0.8564 - loss: 0.5157 - val_accuracy: 0.7445 - val_loss: 0.9348\n",
      "Epoch 48/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 105ms/step - accuracy: 0.8577 - loss: 0.5128 - val_accuracy: 0.7456 - val_loss: 0.9324\n",
      "Epoch 49/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 105ms/step - accuracy: 0.8569 - loss: 0.5149 - val_accuracy: 0.7464 - val_loss: 0.9344\n",
      "Epoch 50/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 114ms/step - accuracy: 0.8584 - loss: 0.5096 - val_accuracy: 0.7482 - val_loss: 0.9285\n",
      "Epoch 51/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 124ms/step - accuracy: 0.8592 - loss: 0.5055 - val_accuracy: 0.7472 - val_loss: 0.9324\n",
      "Epoch 52/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 98ms/step - accuracy: 0.8615 - loss: 0.4985 - val_accuracy: 0.7482 - val_loss: 0.9301\n",
      "Epoch 53/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 97ms/step - accuracy: 0.8616 - loss: 0.4966 - val_accuracy: 0.7483 - val_loss: 0.9297\n",
      "Epoch 54/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 99ms/step - accuracy: 0.8627 - loss: 0.4930 - val_accuracy: 0.7479 - val_loss: 0.9317\n",
      "Epoch 55/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 99ms/step - accuracy: 0.8614 - loss: 0.4959 - val_accuracy: 0.7460 - val_loss: 0.9356\n",
      "Epoch 56/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 98ms/step - accuracy: 0.8638 - loss: 0.4894 - val_accuracy: 0.7483 - val_loss: 0.9312\n",
      "Epoch 57/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 97ms/step - accuracy: 0.8644 - loss: 0.4877 - val_accuracy: 0.7462 - val_loss: 0.9355\n",
      "Epoch 58/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 97ms/step - accuracy: 0.8655 - loss: 0.4836 - val_accuracy: 0.7505 - val_loss: 0.9275\n",
      "Epoch 59/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 96ms/step - accuracy: 0.8680 - loss: 0.4740 - val_accuracy: 0.7504 - val_loss: 0.9270\n",
      "Epoch 60/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 97ms/step - accuracy: 0.8686 - loss: 0.4727 - val_accuracy: 0.7501 - val_loss: 0.9324\n",
      "Epoch 61/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - accuracy: 0.8697 - loss: 0.4675 - val_accuracy: 0.7510 - val_loss: 0.9336\n",
      "Epoch 62/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 100ms/step - accuracy: 0.8699 - loss: 0.4678 - val_accuracy: 0.7502 - val_loss: 0.9311\n",
      "Epoch 63/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 94ms/step - accuracy: 0.8711 - loss: 0.4637 - val_accuracy: 0.7497 - val_loss: 0.9355\n",
      "Epoch 64/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 98ms/step - accuracy: 0.8724 - loss: 0.4578 - val_accuracy: 0.7498 - val_loss: 0.9397\n",
      "Epoch 65/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 98ms/step - accuracy: 0.8728 - loss: 0.4569 - val_accuracy: 0.7490 - val_loss: 0.9417\n",
      "Epoch 66/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 100ms/step - accuracy: 0.8752 - loss: 0.4480 - val_accuracy: 0.7503 - val_loss: 0.9390\n",
      "Epoch 67/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 102ms/step - accuracy: 0.8732 - loss: 0.4536 - val_accuracy: 0.7507 - val_loss: 0.9384\n",
      "Epoch 68/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 99ms/step - accuracy: 0.8750 - loss: 0.4515 - val_accuracy: 0.7510 - val_loss: 0.9411\n",
      "Epoch 69/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 99ms/step - accuracy: 0.8769 - loss: 0.4430 - val_accuracy: 0.7513 - val_loss: 0.9411\n",
      "Epoch 70/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 99ms/step - accuracy: 0.8775 - loss: 0.4402 - val_accuracy: 0.7492 - val_loss: 0.9485\n",
      "Epoch 71/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 101ms/step - accuracy: 0.8771 - loss: 0.4413 - val_accuracy: 0.7497 - val_loss: 0.9532\n",
      "Epoch 72/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 101ms/step - accuracy: 0.8802 - loss: 0.4308 - val_accuracy: 0.7495 - val_loss: 0.9528\n",
      "Epoch 73/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 99ms/step - accuracy: 0.8803 - loss: 0.4300 - val_accuracy: 0.7510 - val_loss: 0.9538\n",
      "Epoch 74/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 94ms/step - accuracy: 0.8819 - loss: 0.4240 - val_accuracy: 0.7495 - val_loss: 0.9543\n",
      "Epoch 75/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 99ms/step - accuracy: 0.8822 - loss: 0.4225 - val_accuracy: 0.7486 - val_loss: 0.9594\n",
      "Epoch 76/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 100ms/step - accuracy: 0.8835 - loss: 0.4187 - val_accuracy: 0.7516 - val_loss: 0.9570\n",
      "Epoch 77/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 100ms/step - accuracy: 0.8837 - loss: 0.4164 - val_accuracy: 0.7491 - val_loss: 0.9625\n",
      "Epoch 78/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 100ms/step - accuracy: 0.8846 - loss: 0.4150 - val_accuracy: 0.7501 - val_loss: 0.9642\n",
      "Epoch 79/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 103ms/step - accuracy: 0.8860 - loss: 0.4113 - val_accuracy: 0.7475 - val_loss: 0.9727\n",
      "Epoch 80/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 102ms/step - accuracy: 0.8868 - loss: 0.4075 - val_accuracy: 0.7488 - val_loss: 0.9766\n",
      "Epoch 81/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 100ms/step - accuracy: 0.8869 - loss: 0.4071 - val_accuracy: 0.7484 - val_loss: 0.9780\n",
      "Epoch 82/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 102ms/step - accuracy: 0.8894 - loss: 0.3980 - val_accuracy: 0.7471 - val_loss: 0.9846\n",
      "Epoch 83/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 104ms/step - accuracy: 0.8882 - loss: 0.4007 - val_accuracy: 0.7485 - val_loss: 0.9853\n",
      "Epoch 84/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 96ms/step - accuracy: 0.8886 - loss: 0.3973 - val_accuracy: 0.7483 - val_loss: 0.9835\n",
      "Epoch 85/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.8902 - loss: 0.3946 - val_accuracy: 0.7467 - val_loss: 0.9893\n",
      "Epoch 86/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 130ms/step - accuracy: 0.8908 - loss: 0.3915 - val_accuracy: 0.7453 - val_loss: 0.9970\n",
      "Epoch 87/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 128ms/step - accuracy: 0.8916 - loss: 0.3879 - val_accuracy: 0.7468 - val_loss: 0.9993\n",
      "Epoch 88/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 118ms/step - accuracy: 0.8921 - loss: 0.3860 - val_accuracy: 0.7461 - val_loss: 1.0024\n",
      "Epoch 89/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 116ms/step - accuracy: 0.8934 - loss: 0.3818 - val_accuracy: 0.7466 - val_loss: 1.0047\n",
      "Epoch 90/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 116ms/step - accuracy: 0.8940 - loss: 0.3784 - val_accuracy: 0.7470 - val_loss: 1.0058\n",
      "Epoch 91/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 116ms/step - accuracy: 0.8938 - loss: 0.3806 - val_accuracy: 0.7454 - val_loss: 1.0136\n",
      "Epoch 92/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 116ms/step - accuracy: 0.8960 - loss: 0.3724 - val_accuracy: 0.7453 - val_loss: 1.0182\n",
      "Epoch 93/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 100ms/step - accuracy: 0.8968 - loss: 0.3707 - val_accuracy: 0.7442 - val_loss: 1.0256\n",
      "Epoch 94/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 100ms/step - accuracy: 0.8973 - loss: 0.3683 - val_accuracy: 0.7446 - val_loss: 1.0236\n",
      "Epoch 95/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 99ms/step - accuracy: 0.8982 - loss: 0.3650 - val_accuracy: 0.7461 - val_loss: 1.0253\n",
      "Epoch 96/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 100ms/step - accuracy: 0.8983 - loss: 0.3641 - val_accuracy: 0.7449 - val_loss: 1.0326\n",
      "Epoch 97/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 100ms/step - accuracy: 0.8990 - loss: 0.3622 - val_accuracy: 0.7446 - val_loss: 1.0407\n",
      "Epoch 98/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 100ms/step - accuracy: 0.9006 - loss: 0.3580 - val_accuracy: 0.7444 - val_loss: 1.0468\n",
      "Epoch 99/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 100ms/step - accuracy: 0.9015 - loss: 0.3536 - val_accuracy: 0.7444 - val_loss: 1.0514\n",
      "Epoch 100/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 100ms/step - accuracy: 0.9019 - loss: 0.3515 - val_accuracy: 0.7450 - val_loss: 1.0480\n",
      "Epoch 101/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 100ms/step - accuracy: 0.9029 - loss: 0.3485 - val_accuracy: 0.7424 - val_loss: 1.0623\n",
      "Epoch 102/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 100ms/step - accuracy: 0.9027 - loss: 0.3501 - val_accuracy: 0.7447 - val_loss: 1.0612\n",
      "Epoch 103/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 101ms/step - accuracy: 0.9032 - loss: 0.3464 - val_accuracy: 0.7439 - val_loss: 1.0651\n",
      "Epoch 104/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 101ms/step - accuracy: 0.9047 - loss: 0.3414 - val_accuracy: 0.7429 - val_loss: 1.0680\n",
      "Epoch 105/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 101ms/step - accuracy: 0.9049 - loss: 0.3389 - val_accuracy: 0.7425 - val_loss: 1.0737\n",
      "Epoch 106/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 100ms/step - accuracy: 0.9057 - loss: 0.3384 - val_accuracy: 0.7420 - val_loss: 1.0811\n",
      "Epoch 107/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 100ms/step - accuracy: 0.9065 - loss: 0.3372 - val_accuracy: 0.7419 - val_loss: 1.0878\n",
      "Epoch 108/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 101ms/step - accuracy: 0.9077 - loss: 0.3329 - val_accuracy: 0.7416 - val_loss: 1.0908\n",
      "Epoch 109/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 101ms/step - accuracy: 0.9078 - loss: 0.3312 - val_accuracy: 0.7420 - val_loss: 1.0941\n",
      "Epoch 110/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 98ms/step - accuracy: 0.9085 - loss: 0.3279 - val_accuracy: 0.7417 - val_loss: 1.0976\n",
      "Epoch 111/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 97ms/step - accuracy: 0.9098 - loss: 0.3250 - val_accuracy: 0.7418 - val_loss: 1.1039\n",
      "Epoch 112/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 96ms/step - accuracy: 0.9107 - loss: 0.3236 - val_accuracy: 0.7422 - val_loss: 1.1037\n",
      "Epoch 113/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 98ms/step - accuracy: 0.9110 - loss: 0.3201 - val_accuracy: 0.7419 - val_loss: 1.1123\n",
      "Epoch 114/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 103ms/step - accuracy: 0.9125 - loss: 0.3146 - val_accuracy: 0.7398 - val_loss: 1.1299\n",
      "Epoch 115/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 100ms/step - accuracy: 0.9114 - loss: 0.3167 - val_accuracy: 0.7403 - val_loss: 1.1272\n",
      "Epoch 116/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 100ms/step - accuracy: 0.9127 - loss: 0.3131 - val_accuracy: 0.7405 - val_loss: 1.1286\n",
      "Epoch 117/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 100ms/step - accuracy: 0.9136 - loss: 0.3103 - val_accuracy: 0.7408 - val_loss: 1.1296\n",
      "Epoch 118/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 100ms/step - accuracy: 0.9134 - loss: 0.3101 - val_accuracy: 0.7405 - val_loss: 1.1441\n",
      "Epoch 119/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 101ms/step - accuracy: 0.9150 - loss: 0.3072 - val_accuracy: 0.7374 - val_loss: 1.1571\n",
      "Epoch 120/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 114ms/step - accuracy: 0.9145 - loss: 0.3072 - val_accuracy: 0.7389 - val_loss: 1.1592\n",
      "Epoch 121/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 109ms/step - accuracy: 0.9160 - loss: 0.3019 - val_accuracy: 0.7372 - val_loss: 1.1618\n",
      "Epoch 122/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 111ms/step - accuracy: 0.9174 - loss: 0.2982 - val_accuracy: 0.7381 - val_loss: 1.1648\n",
      "Epoch 123/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 108ms/step - accuracy: 0.9172 - loss: 0.2984 - val_accuracy: 0.7378 - val_loss: 1.1760\n",
      "Epoch 124/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 108ms/step - accuracy: 0.9179 - loss: 0.2962 - val_accuracy: 0.7385 - val_loss: 1.1674\n",
      "Epoch 125/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 111ms/step - accuracy: 0.9184 - loss: 0.2947 - val_accuracy: 0.7380 - val_loss: 1.1822\n",
      "Epoch 126/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 103ms/step - accuracy: 0.9186 - loss: 0.2921 - val_accuracy: 0.7370 - val_loss: 1.1842\n",
      "Epoch 127/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 107ms/step - accuracy: 0.9197 - loss: 0.2895 - val_accuracy: 0.7376 - val_loss: 1.1959\n",
      "Epoch 128/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 111ms/step - accuracy: 0.9206 - loss: 0.2867 - val_accuracy: 0.7379 - val_loss: 1.1996\n",
      "Epoch 129/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 109ms/step - accuracy: 0.9203 - loss: 0.2864 - val_accuracy: 0.7377 - val_loss: 1.2075\n",
      "Epoch 130/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 108ms/step - accuracy: 0.9212 - loss: 0.2855 - val_accuracy: 0.7371 - val_loss: 1.2050\n",
      "Epoch 131/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 112ms/step - accuracy: 0.9224 - loss: 0.2800 - val_accuracy: 0.7375 - val_loss: 1.2085\n",
      "Epoch 132/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.9221 - loss: 0.2803 - val_accuracy: 0.7370 - val_loss: 1.2156\n",
      "Epoch 133/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.9229 - loss: 0.2790 - val_accuracy: 0.7387 - val_loss: 1.2237\n",
      "Epoch 134/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 112ms/step - accuracy: 0.9232 - loss: 0.2782 - val_accuracy: 0.7371 - val_loss: 1.2327\n",
      "Epoch 135/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 103ms/step - accuracy: 0.9237 - loss: 0.2760 - val_accuracy: 0.7358 - val_loss: 1.2306\n",
      "Epoch 136/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 111ms/step - accuracy: 0.9238 - loss: 0.2752 - val_accuracy: 0.7344 - val_loss: 1.2473\n",
      "Epoch 137/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 101ms/step - accuracy: 0.9243 - loss: 0.2731 - val_accuracy: 0.7345 - val_loss: 1.2465\n",
      "Epoch 138/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 106ms/step - accuracy: 0.9253 - loss: 0.2711 - val_accuracy: 0.7360 - val_loss: 1.2445\n",
      "Epoch 139/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 102ms/step - accuracy: 0.9250 - loss: 0.2703 - val_accuracy: 0.7356 - val_loss: 1.2499\n",
      "Epoch 140/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 102ms/step - accuracy: 0.9263 - loss: 0.2662 - val_accuracy: 0.7344 - val_loss: 1.2679\n",
      "Epoch 141/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 103ms/step - accuracy: 0.9271 - loss: 0.2646 - val_accuracy: 0.7359 - val_loss: 1.2626\n",
      "Epoch 142/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 103ms/step - accuracy: 0.9277 - loss: 0.2622 - val_accuracy: 0.7359 - val_loss: 1.2669\n",
      "Epoch 143/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 103ms/step - accuracy: 0.9274 - loss: 0.2632 - val_accuracy: 0.7341 - val_loss: 1.2791\n",
      "Epoch 144/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 103ms/step - accuracy: 0.9284 - loss: 0.2589 - val_accuracy: 0.7362 - val_loss: 1.2760\n",
      "Epoch 145/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 103ms/step - accuracy: 0.9280 - loss: 0.2600 - val_accuracy: 0.7352 - val_loss: 1.2853\n",
      "Epoch 146/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 102ms/step - accuracy: 0.9296 - loss: 0.2550 - val_accuracy: 0.7349 - val_loss: 1.2963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 102ms/step - accuracy: 0.9297 - loss: 0.2537 - val_accuracy: 0.7355 - val_loss: 1.2932\n",
      "Epoch 148/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 102ms/step - accuracy: 0.9301 - loss: 0.2539 - val_accuracy: 0.7344 - val_loss: 1.2966\n",
      "Epoch 149/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 103ms/step - accuracy: 0.9306 - loss: 0.2525 - val_accuracy: 0.7357 - val_loss: 1.3038\n",
      "Epoch 150/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 103ms/step - accuracy: 0.9310 - loss: 0.2501 - val_accuracy: 0.7347 - val_loss: 1.3106\n",
      "Epoch 151/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 103ms/step - accuracy: 0.9309 - loss: 0.2497 - val_accuracy: 0.7352 - val_loss: 1.3174\n",
      "Epoch 152/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 104ms/step - accuracy: 0.9311 - loss: 0.2491 - val_accuracy: 0.7339 - val_loss: 1.3240\n",
      "Epoch 153/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 111ms/step - accuracy: 0.9322 - loss: 0.2454 - val_accuracy: 0.7341 - val_loss: 1.3330\n",
      "Epoch 154/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 106ms/step - accuracy: 0.9330 - loss: 0.2435 - val_accuracy: 0.7345 - val_loss: 1.3346\n",
      "Epoch 155/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 110ms/step - accuracy: 0.9331 - loss: 0.2437 - val_accuracy: 0.7356 - val_loss: 1.3319\n",
      "Epoch 156/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 109ms/step - accuracy: 0.9339 - loss: 0.2412 - val_accuracy: 0.7342 - val_loss: 1.3459\n",
      "Epoch 157/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 104ms/step - accuracy: 0.9337 - loss: 0.2415 - val_accuracy: 0.7333 - val_loss: 1.3561\n",
      "Epoch 158/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 106ms/step - accuracy: 0.9338 - loss: 0.2397 - val_accuracy: 0.7326 - val_loss: 1.3557\n",
      "Epoch 159/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 106ms/step - accuracy: 0.9342 - loss: 0.2383 - val_accuracy: 0.7345 - val_loss: 1.3569\n",
      "Epoch 160/160\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 104ms/step - accuracy: 0.9347 - loss: 0.2368 - val_accuracy: 0.7334 - val_loss: 1.3671\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: أنا أحد\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: اهل هذه الأعراة لك.\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: الجو حار.\n",
      "\n",
      "-\n",
      "Input sentence: Jump!\n",
      "Decoded sentence: اسمع!\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: استمر.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: استمر.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: استمر.\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: الجو حار.\n",
      "\n",
      "-\n",
      "Input sentence: Hurry!\n",
      "Decoded sentence: استمرت الثلم.\n",
      "\n",
      "-\n",
      "Input sentence: Hurry!\n",
      "Decoded sentence: استمرت الثلم.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: أنا أحد.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: أنا فهي.\n",
      "\n",
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: اسمع!\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: انتبه\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: استمر.\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: استمر.\n",
      "\n",
      "-\n",
      "Input sentence: He ran.\n",
      "Decoded sentence: إنه مري.\n",
      "\n",
      "-\n",
      "Input sentence: I know.\n",
      "Decoded sentence: أنا أحبك.\n",
      "\n",
      "-\n",
      "Input sentence: I know.\n",
      "Decoded sentence: أنا أحبك.\n",
      "\n",
      "-\n",
      "Input sentence: I know.\n",
      "Decoded sentence: أنا أحبك.\n",
      "\n",
      "-\n",
      "Input sentence: I'm 19.\n",
      "Decoded sentence: أنا في البيت\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: أنا في البيت\n",
      "\n",
      "-\n",
      "Input sentence: Listen.\n",
      "Decoded sentence: استمر.\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: استيدتي.\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: استمر.\n",
      "\n",
      "-\n",
      "Input sentence: Thanks.\n",
      "Decoded sentence: الجو حار.\n",
      "\n",
      "-\n",
      "Input sentence: Why me?\n",
      "Decoded sentence: كيف حال ذلك؟\n",
      "\n",
      "-\n",
      "Input sentence: Awesome!\n",
      "Decoded sentence: إنه مريض.\n",
      "\n",
      "-\n",
      "Input sentence: Be cool.\n",
      "Decoded sentence: استمر.\n",
      "\n",
      "-\n",
      "Input sentence: Call me.\n",
      "Decoded sentence: استمر.\n",
      "\n",
      "-\n",
      "Input sentence: Call me.\n",
      "Decoded sentence: استمر.\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: توم الحس.\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: توم الحس.\n",
      "\n",
      "-\n",
      "Input sentence: Come on!\n",
      "Decoded sentence: توم الحس.\n",
      "\n",
      "-\n",
      "Input sentence: Come on!\n",
      "Decoded sentence: توم الحس.\n",
      "\n",
      "-\n",
      "Input sentence: Come on!\n",
      "Decoded sentence: توم الحس.\n",
      "\n",
      "-\n",
      "Input sentence: Get out!\n",
      "Decoded sentence: اسمع!\n",
      "\n",
      "-\n",
      "Input sentence: Get out!\n",
      "Decoded sentence: اسمع!\n",
      "\n",
      "-\n",
      "Input sentence: Get out.\n",
      "Decoded sentence: اسمع!\n",
      "\n",
      "-\n",
      "Input sentence: Go away.\n",
      "Decoded sentence: اسمع!\n",
      "\n",
      "-\n",
      "Input sentence: Go away.\n",
      "Decoded sentence: اسمع!\n",
      "\n",
      "-\n",
      "Input sentence: Go away.\n",
      "Decoded sentence: اسمع!\n",
      "\n",
      "-\n",
      "Input sentence: Goodbye!\n",
      "Decoded sentence: استمر.\n",
      "\n",
      "-\n",
      "Input sentence: He came.\n",
      "Decoded sentence: إنه مريض.\n",
      "\n",
      "-\n",
      "Input sentence: He runs.\n",
      "Decoded sentence: إنه مريض.\n",
      "\n",
      "-\n",
      "Input sentence: Help me!\n",
      "Decoded sentence: الجو حار.\n",
      "\n",
      "-\n",
      "Input sentence: Help me.\n",
      "Decoded sentence: الجو حار.\n",
      "\n",
      "-\n",
      "Input sentence: I'm sad.\n",
      "Decoded sentence: أنا في البيت\n",
      "\n",
      "-\n",
      "Input sentence: Me, too.\n",
      "Decoded sentence: انت محلدق.\n",
      "\n",
      "-\n",
      "Input sentence: Shut up!\n",
      "Decoded sentence: استمر.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "\n",
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 160 # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 10000  # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "\n",
    "## Prepare the data\n",
    "\n",
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(\"ara_eng.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    parts = line.split(\"\\t\")\n",
    "    if len(parts) != 2:  # Ensure that each line has two parts (input and target)\n",
    "        continue  # Skip lines with incorrect format\n",
    "    input_text, target_text = parts\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print(\"Number of samples:\", len(input_texts))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
    "\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype=\"float32\",\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype=\"float32\",\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype=\"float32\",\n",
    ")\n",
    "try:\n",
    "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "        for t, char in enumerate(input_text):\n",
    "            encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "        encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "        for t, char in enumerate(target_text):\n",
    "            # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "            decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "            if t > 0:\n",
    "                # decoder_target_data will be ahead by one timestep\n",
    "                # and will not include the start character.\n",
    "                decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "        decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "        decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
    "\n",
    "    \"\"\"\n",
    "    ## Build the model\n",
    "    \"\"\"\n",
    "\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
    "    encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "    # We discard encoder_outputs and only keep the states.\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Set up the decoder, using encoder_states as initial state.\n",
    "    decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "    # We set up our decoder to return full output sequences,\n",
    "    # and to return internal states as well. We don't use the\n",
    "    # return states in the training model, but we will use them in inference.\n",
    "    decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # Define the model that will turn\n",
    "    # encoder_input_data & decoder_input_data into decoder_target_data\n",
    "    model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    \"\"\"\n",
    "    ## Train the model\n",
    "    \"\"\"\n",
    "    #\n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    model.fit(\n",
    "        [encoder_input_data, decoder_input_data],\n",
    "        decoder_target_data,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.2,\n",
    "    )\n",
    "    # Save model\n",
    "    model.save(\"model_10.keras\")\n",
    "\n",
    "\n",
    "    # Define sampling models\n",
    "    # Restore the model and construct the encoder and decoder.\n",
    "    model = keras.models.load_model(\"model_10.keras\")\n",
    "\n",
    "    encoder_inputs = model.input[0]  # input_1\n",
    "    encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
    "    encoder_states = [state_h_enc, state_c_enc]\n",
    "    encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "    decoder_inputs = model.input[1]  # input_2\n",
    "    decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
    "    decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_lstm = model.layers[3]\n",
    "    decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "        decoder_inputs, initial_state=decoder_states_inputs\n",
    "    )\n",
    "    decoder_states = [state_h_dec, state_c_dec]\n",
    "    decoder_dense = model.layers[4]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = keras.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    "    )\n",
    "\n",
    "    # Reverse-lookup token index to decode sequences back to\n",
    "    # something readable.\n",
    "    reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "    reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "    def decode_sequence(input_seq):\n",
    "        # Encode the input as state vectors.\n",
    "        states_value = encoder_model.predict(input_seq, verbose=0)\n",
    "\n",
    "        # Generate empty target sequence of length 1.\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        # Populate the first character of target sequence with the start character.\n",
    "        target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "        # Sampling loop for a batch of sequences\n",
    "        # (to simplify, here we assume a batch of size 1).\n",
    "        stop_condition = False\n",
    "        decoded_sentence = \"\"\n",
    "        while not stop_condition:\n",
    "            output_tokens, h, c = decoder_model.predict(\n",
    "                [target_seq] + states_value, verbose=0\n",
    "            )\n",
    "\n",
    "            # Sample a token\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "            decoded_sentence += sampled_char\n",
    "\n",
    "            # Exit condition: either hit max length\n",
    "            # or find stop character.\n",
    "            if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "                stop_condition = True\n",
    "\n",
    "            # Update the target sequence (of length 1).\n",
    "            target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "            target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "            # Update states\n",
    "            states_value = [h, c]\n",
    "        return decoded_sentence\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    You can now generate decoded sentences as such:\n",
    "    \"\"\"\n",
    "\n",
    "    for seq_index in range(50):\n",
    "        # Take one sequence (part of the training set)\n",
    "        # for trying out decoding.\n",
    "        input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
    "        decoded_sentence = decode_sequence(input_seq)\n",
    "        print(\"-\")\n",
    "        print(\"Input sentence:\", input_texts[seq_index])\n",
    "        print(\"Decoded sentence:\", decoded_sentence)\n",
    "except:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ec0478c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Function to tokenize text and translate it\n",
    "def translate_text():\n",
    "    # Get text from entry widget\n",
    "    input_text = entry.get('1.0', tk.END)\n",
    "\n",
    "    # Tokenize the input text into words\n",
    "    input_words = word_tokenize(input_text)\n",
    "\n",
    "    # Initialize an empty string for translated output\n",
    "    translated_output = \"\"\n",
    "\n",
    "    # Loop through each word in the input text\n",
    "    for word in input_words:\n",
    "        # Encode the word as one-hot vector\n",
    "        encoder_input_data = np.zeros((1, len(word), num_encoder_tokens), dtype=\"float32\")\n",
    "        for t, char in enumerate(word):\n",
    "            encoder_input_data[0, t, input_token_index[char]] = 1.0\n",
    "\n",
    "        # Translate the word using the encoder-decoder model\n",
    "        translated_word = decode_sequence(encoder_input_data)\n",
    "\n",
    "        # Append the translated word to the output\n",
    "        translated_output += translated_word\n",
    "        \n",
    "    tab1_display.insert(tk.END,translated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795d2d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize text and translate it\n",
    "def translate_text_2():\n",
    "    # Get text from entry widget\n",
    "    input_text = entry.get('1.0', tk.END)\n",
    "\n",
    "    # Tokenize the input text into words\n",
    "    input_words = word_tokenize(input_text)\n",
    "\n",
    "    # Initialize an empty string for translated output\n",
    "    translated_output = \"\"\n",
    "\n",
    "    # Loop through each word in the input text\n",
    "    for word in input_words:\n",
    "        # Encode the word as one-hot vector\n",
    "        encoder_input_data = np.zeros((1, len(word), num_encoder_tokens), dtype=\"float32\")\n",
    "        for t, char in enumerate(word):\n",
    "            encoder_input_data[0, t, input_token_index[char]] = 1.0\n",
    "\n",
    "        # Translate the word using the encoder-decoder model\n",
    "        translated_word = decode_sequence(encoder_input_data)\n",
    "\n",
    "        # Append the translated word to the output\n",
    "        translated_output += translated_word\n",
    "        \n",
    "    tab1_display.insert(tk.END,translated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ecfdc394",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Tk()\n",
    "window.title(\"Valorant Team\")\n",
    "window.geometry(\"900x500\")\n",
    "# TAB LAYOUT\n",
    "tab_control = ttk.Notebook(window)\n",
    " \n",
    "tab1 = ttk.Frame(tab_control)\n",
    "tab2 = ttk.Frame(tab_control)\n",
    "\n",
    "# ADD TABS TO NOTEBOOK\n",
    "tab_control.add(tab1, text=f'{\"Home\":^20s}')\n",
    "tab_control.add(tab2, text=f'{\"File\":^20s}')\n",
    "tab_control.pack(expand=1, fill='both')\n",
    "\n",
    "\n",
    "# MAIN NLP TAB\n",
    "l1=Label(tab1,text=\"Enter Text\")\n",
    "l1.grid(row=1,column=1)\n",
    "\n",
    "entry=ScrolledText(tab1,height=10,width=110)\n",
    "entry.grid(row=2,column=0,columnspan=3,padx=5,pady=5)\n",
    "\n",
    "\n",
    "def clear_text():\n",
    "    entry.delete('1.0',END)\n",
    "    \n",
    "def clear_display_result():\n",
    "    tab1_display.delete('1.0',END)\n",
    "    \n",
    "# Clear Text  with position 1.0\n",
    "def clear_text_file():\n",
    "    displayed_file.delete('1.0',END)\n",
    "\n",
    "# Clear Result of Functions\n",
    "def clear_text_result():\n",
    "    tab2_display_text.delete('1.0',END)\n",
    "    \n",
    "    \n",
    "# Functions for TAB 2 FILE PROCESSER\n",
    "# Open File to Read and Process\n",
    "\n",
    "def openfiles():\n",
    "    file1 = tkinter.filedialog.askopenfilename(filetypes=((\"Text Files\",\".txt\"),(\"All files\",\"*\")))\n",
    "    read_text = open(file1).read()\n",
    "    displayed_file.insert(tk.END,read_text)\n",
    "\n",
    "# BUTTONS\n",
    "button1=Button(tab1,text=\"Reset\",command=clear_text, width=12,bg='#c71585',fg='#fff')\n",
    "button1.grid(row=4,column=1,padx=10,pady=10)\n",
    "\n",
    "button2=Button(tab1,text=\"Summarize\",command=get_summarize, width=12,bg='#c71585',fg='#fff')\n",
    "button2.grid(row=4,column=0,padx=10,pady=10)\n",
    "\n",
    "button3=Button(tab1,text=\"Clear Result\", command=clear_display_result,width=12,bg='#c71585',fg='#fff')\n",
    "button3.grid(row=4,column=2,padx=10,pady=10)\n",
    "\n",
    "translate_button = Button(tab1, text=\"Translate!\",width=12,command=translate_text,bg='#c71585',fg='#fff')\n",
    "translate_button.grid(row=5, column=0, padx=10,pady=10)\n",
    "\n",
    "b4=Button(tab1,text=\"analyse\", width=12,command=Sentiment_Analysis,bg='#c71585',fg='#fff')\n",
    "b4.grid(row=5,column=1,padx=10,pady=10)\n",
    "\n",
    "b5=Button(tab1,text=\"ner\", width=12,command=ner,bg='#c71585',fg='#fff')\n",
    "b5.grid(row=5,column=2,padx=10,pady=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# BUTTONS FOR SECOND TAB/FILE READING TAB\n",
    "b0=Button(tab2,text=\"Open File\", width=12,command=openfiles,bg='#c71585',fg='#fff')\n",
    "b0.grid(row=3,column=0,padx=10,pady=10)\n",
    "\n",
    "b1=Button(tab2,text=\"Reset \", width=12,command=clear_text_file,bg='#c71585',fg='#fff')\n",
    "b1.grid(row=3,column=1,padx=10,pady=10)\n",
    "\n",
    "b2=Button(tab2,text=\"Summarize\", width=12,command=get_file_summary,bg='#c71585',fg='#fff')\n",
    "b2.grid(row=3,column=2,padx=10,pady=10)\n",
    "\n",
    "b3=Button(tab2,text=\"Clear Result\", width=12,command=clear_text_result,bg='#c71585',fg='#fff')\n",
    "b3.grid(row=5,column=1,padx=10,pady=10)\n",
    "\n",
    "b4=Button(tab2,text=\"Close\", width=12,command=window.destroy,bg='#c71585',fg='#fff')\n",
    "b4.grid(row=5,column=2,padx=10,pady=10)\n",
    "\n",
    "translate_button = Button(tab2, text=\"Translate!\", width=12,command=translate_text_2,bg='#c71585',fg='#fff')\n",
    "translate_button.grid(row=5, column=0, padx=10,pady=10)\n",
    "\n",
    "b5=Button(tab2,text=\"analyse\", width=12,command=Sentiment_Analysis_file,bg='#c71585',fg='#fff')\n",
    "b5.grid(row=3,column=3,padx=10,pady=10)\n",
    "\n",
    "b5=Button(tab2,text=\"ner\", width=12,command=nerf,bg='#c71585',fg='#fff')\n",
    "b5.grid(row=5,column=3,padx=10,pady=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Display Screen For Result\n",
    "tab1_display = Text(tab1,height=10,width=110)\n",
    "tab1_display.grid(row=7,column=0, columnspan=3,padx=5,pady=5)\n",
    "\n",
    "displayed_file = ScrolledText(tab2,height=10,width=110)# Initial was Text(tab2)\n",
    "\n",
    "displayed_file.grid(row=2,column=0, columnspan=4,padx=5,pady=3)\n",
    "\n",
    "\n",
    "tab2_display_text = ScrolledText(tab2,height=10,width=110)\n",
    "tab2_display_text.grid(row=7,column=0, columnspan=4,padx=5,pady=5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaf0699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33096467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332167ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26a4637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf5f688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68561050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd3cee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa5ca82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54710e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5b6155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03c4766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d4d07f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf5b897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72780e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1194fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3ba4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13196a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03b99f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc1a103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353797f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5308b630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdf8cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4e18eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a55b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0933da78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316f7e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e82f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c7ae0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9bae9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b853414a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47233ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdfb468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c61857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71366ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67e8648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240fe735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838b39d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470c8b93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa83967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e13f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6d3201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805ebc02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52da5803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee922b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54559e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47397460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f88205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c99905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e48fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aef87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdcefab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44f647e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4811e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
